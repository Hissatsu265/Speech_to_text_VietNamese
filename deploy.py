

import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from transformers import WhisperProcessor, WhisperForConditionalGeneration
import torch
import numpy as np
from collections import deque
import librosa

app = FastAPI(title="Vietnamese STT Real-time API")

# CORS ƒë·ªÉ frontend c√≥ th·ªÉ k·∫øt n·ªëi
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- LOAD MODEL ---
print("üîÑ ƒêang load model...")
MODEL_PATH = "./whisper-vietnamese-finetuned/final"
device = "cuda" if torch.cuda.is_available() else "cpu"

processor = WhisperProcessor.from_pretrained(MODEL_PATH)
model = WhisperForConditionalGeneration.from_pretrained(MODEL_PATH).to(device)

# ‚úÖ C·∫§U H√åNH CH·ªêNG L·∫∂P T·ª™
model.config.forced_decoder_ids = None
model.config.suppress_tokens = []

print(f"‚úÖ Model loaded on: {device}")

# --- BUFFER AUDIO ---
class AudioBuffer:
    """Buffer ƒë·ªÉ t√≠ch l≈©y audio chunks tr∆∞·ªõc khi transcribe"""
    def __init__(self, min_duration=2.0, sample_rate=16000):
        self.buffer = deque(maxlen=int(30 * sample_rate))  # Max 30s
        self.min_samples = int(min_duration * sample_rate)  # Min 2s
        self.sample_rate = sample_rate
    
    def add(self, audio_chunk):
        """Th√™m chunk v√†o buffer"""
        self.buffer.extend(audio_chunk)
    
    def get_audio(self):
        """L·∫•y to√†n b·ªô audio trong buffer"""
        if len(self.buffer) >= self.min_samples:
            return np.array(self.buffer, dtype=np.float32)
        return None
    
    def clear(self):
        """X√≥a buffer"""
        self.buffer.clear()

@app.get("/")
def read_root():
    return {
        "status": "‚úÖ Server ƒëang ch·∫°y",
        "model": MODEL_PATH,
        "device": device
    }

@app.get("/health")
def health_check():
    return {"status": "healthy", "device": device}

@app.websocket("/ws/transcribe")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("üìû Client connected!")
    
    audio_buffer = AudioBuffer(min_duration=1.5, sample_rate=16000)
    
    try:
        while True:
            # 1. Nh·∫≠n audio chunk t·ª´ client
            data = await websocket.receive_bytes()
            
            # 2. Chuy·ªÉn bytes ‚Üí numpy array
            audio_chunk = np.frombuffer(data, dtype=np.float32)
            
            # 3. Th√™m v√†o buffer
            audio_buffer.add(audio_chunk)
            
            # 4. N·∫øu ƒë·ªß d·ªØ li·ªáu ‚Üí transcribe
            audio_array = audio_buffer.get_audio()
            
            if audio_array is not None:
                try:
                    # Chu·∫©n h√≥a audio
                    audio_array = librosa.util.normalize(audio_array)
                    
                    # Extract features
                    input_features = processor(
                        audio_array, 
                        sampling_rate=16000, 
                        return_tensors="pt"
                    ).input_features.to(device)
                    
                    # Generate v·ªõi config ch·ªëng l·∫∑p
                    with torch.no_grad():
                        predicted_ids = model.generate(
                            input_features,
                            max_new_tokens=128,
                            num_beams=5,
                            repetition_penalty=1.2,
                            no_repeat_ngram_size=3,
                            temperature=0.0,
                        )
                    
                    # Decode
                    transcription = processor.batch_decode(
                        predicted_ids, 
                        skip_special_tokens=True
                    )[0].strip()
                    
                    # G·ª≠i k·∫øt qu·∫£
                    if transcription:
                        print(f"üé§ Transcription: {transcription}")
                        await websocket.send_json({
                            "text": transcription,
                            "status": "success"
                        })
                        
                        # Clear buffer sau khi transcribe
                        audio_buffer.clear()
                
                except Exception as e:
                    print(f"‚ùå Error during transcription: {e}")
                    await websocket.send_json({
                        "text": "",
                        "status": "error",
                        "message": str(e)
                    })
    
    except WebSocketDisconnect:
        print("üì¥ Client disconnected")
    except Exception as e:
        print(f"‚ùå WebSocket error: {e}")
    finally:
        try:
            await websocket.close()
        except:
            pass

if __name__ == "__main__":
    # ‚úÖ Ngrok setup
    try:
        from pyngrok import ngrok
        
        API_PORT = 8000
        
        # T·∫°o public URL v·ªõi ngrok
        public_url = ngrok.connect(
            API_PORT, 
            "http",
            # ‚úÖ Thay domain c·ªßa b·∫°n v√†o ƒë√¢y (ho·∫∑c b·ªè d√≤ng n√†y ƒë·ªÉ d√πng URL random)
            # domain="your-domain.ngrok-free.app"
        )
        
        print("\n" + "="*60)
        print("üåê NGROK PUBLIC URL")
        print("="*60)
        print(f"üîó {public_url}")
        print(f"üìù WebSocket: {public_url.replace('http', 'ws')}/ws/transcribe")
        print("="*60 + "\n")
        
    except ImportError:
        print("‚ö†Ô∏è  pyngrok not installed. Install: pip install pyngrok")
        print("   Running on localhost only...")
    except Exception as e:
        print(f"‚ö†Ô∏è  Ngrok error: {e}")
        print("   Running on localhost only...")
    
    # Ch·∫°y server
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )