"""
Backend FastAPI cho Speech-to-Text Real-time
Ch·∫°y: python main.py
"""

import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from transformers import WhisperProcessor, WhisperForConditionalGeneration
import torch
import numpy as np
from collections import deque
import librosa

app = FastAPI(title="Vietnamese STT Real-time API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

print("üîÑ ƒêang load model...")
MODEL_PATH = "./final"
device = "cuda" if torch.cuda.is_available() else "cpu"

processor = WhisperProcessor.from_pretrained(MODEL_PATH)
model = WhisperForConditionalGeneration.from_pretrained(MODEL_PATH).to(device)

model.config.forced_decoder_ids = None
model.config.suppress_tokens = []

print(f"‚úÖ Model loaded on: {device}")

class AudioBuffer:
    def __init__(self, min_duration=2.0, sample_rate=16000):
        self.buffer = deque(maxlen=int(30 * sample_rate))
        self.min_samples = int(min_duration * sample_rate)  
        self.sample_rate = sample_rate
    
    def add(self, audio_chunk):
        """Th√™m chunk v√†o buffer"""
        self.buffer.extend(audio_chunk)
    
    def get_audio(self):
        """L·∫•y to√†n b·ªô audio trong buffer"""
        if len(self.buffer) >= self.min_samples:
            return np.array(self.buffer, dtype=np.float32)
        return None
    
    def clear(self):
        """X√≥a buffer"""
        self.buffer.clear()

@app.get("/")
def read_root():
    return {
        "status": "‚úÖ Server ƒëang ch·∫°y",
        "model": MODEL_PATH,
        "device": device
    }

@app.get("/health")
def health_check():
    return {"status": "healthy", "device": device}

@app.websocket("/ws/transcribe")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    print("üìû Client connected!")
    
    audio_buffer = AudioBuffer(min_duration=1.5, sample_rate=16000)
    
    try:
        while True:
            # 1. Nh·∫≠n audio chunk t·ª´ client
            data = await websocket.receive_bytes()
            
            # 2. Chuy·ªÉn bytes ‚Üí numpy array
            audio_chunk = np.frombuffer(data, dtype=np.float32)
            
            # 3. Th√™m v√†o buffer
            audio_buffer.add(audio_chunk)
            
            # 4. N·∫øu ƒë·ªß d·ªØ li·ªáu ‚Üí transcribe
            audio_array = audio_buffer.get_audio()
            
            if audio_array is not None:
                try:
                    # Chu·∫©n h√≥a audio
                    audio_array = librosa.util.normalize(audio_array)
                    
                    # Extract features
                    input_features = processor(
                        audio_array, 
                        sampling_rate=16000, 
                        return_tensors="pt"
                    ).input_features.to(device)
                    
                    # Generate v·ªõi config ch·ªëng l·∫∑p
                    with torch.no_grad():
                        predicted_ids = model.generate(
                            input_features,
                            max_new_tokens=128,
                            num_beams=5,
                            repetition_penalty=1.2,
                            no_repeat_ngram_size=3,
                            temperature=0.0,
                        )
                    
                    # Decode
                    transcription = processor.batch_decode(
                        predicted_ids, 
                        skip_special_tokens=True
                    )[0].strip()
                    
                    # G·ª≠i k·∫øt qu·∫£
                    if transcription:
                        print(f"üé§ Transcription: {transcription}")
                        await websocket.send_json({
                            "text": transcription,
                            "status": "success"
                        })
                        
                        # Clear buffer sau khi transcribe
                        audio_buffer.clear()
                
                except Exception as e:
                    print(f"‚ùå Error during transcription: {e}")
                    await websocket.send_json({
                        "text": "",
                        "status": "error",
                        "message": str(e)
                    })
    
    except WebSocketDisconnect:
        print("üì¥ Client disconnected")
    except Exception as e:
        print(f"‚ùå WebSocket error: {e}")
    finally:
        try:
            await websocket.close()
        except:
            pass

if __name__ == "__main__":
    # ‚úÖ Ngrok setup
    try:
        from pyngrok import ngrok
        
        API_PORT = 8000
        
        # T·∫°o public URL v·ªõi ngrok
        tunnel = ngrok.connect(
            API_PORT, 
            "http",
            # ‚úÖ Thay domain c·ªßa b·∫°n v√†o ƒë√¢y (ho·∫∑c comment ƒë·ªÉ d√πng URL random)
            domain="hailee-unrepresentational-ronnie.ngrok-free.dev"
        )
        
        # ‚úÖ L·∫•y public URL t·ª´ tunnel object
        public_url = tunnel.public_url
        ws_url = public_url.replace('https://', 'wss://').replace('http://', 'ws://')
        
        print("\n" + "="*60)
        print("üåê NGROK PUBLIC URL")
        print("="*60)
        print(f"üîó HTTP:  {public_url}")
        print(f"üìù WebSocket: {ws_url}/ws/transcribe")
        print("="*60)
        print(f"üí° M·ªü frontend v√† paste URL n√†y v√†o √¥ WebSocket URL:")
        print(f"   {ws_url}/ws/transcribe")
        print("="*60 + "\n")
        
    except ImportError:
        print("‚ö†Ô∏è  pyngrok not installed. Install: pip install pyngrok")
        print("   Running on localhost only...")
    except Exception as e:
        print(f"‚ö†Ô∏è  Ngrok error: {e}")
        print("   Running on localhost only...")
    
    # Ch·∫°y server
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )